{"cells":[{"cell_type":"markdown","id":"978f5020","metadata":{"id":"978f5020"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"id":"276ee5f6","metadata":{"id":"276ee5f6"},"outputs":[],"source":["# Import libraries\n","import os\n","import pickle\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model  \n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add\n","\n","# Importing libraries\n","from tensorflow import keras\n","import tkinter as tk\n","from PIL import Image, ImageTk\n","from tkinter import filedialog\n","from tensorflow.keras.utils import img_to_array\n","from keras.applications.vgg16 import preprocess_input"]},{"cell_type":"markdown","id":"56ab6706","metadata":{"id":"56ab6706"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"id":"adca78ac","metadata":{"id":"adca78ac"},"outputs":[],"source":["model_vgg = VGG16()\n","model_vgg = Model(inputs=model_vgg.inputs, outputs=model_vgg.layers[-2].output)"]},{"cell_type":"code","execution_count":null,"id":"28ba5615","metadata":{"id":"28ba5615"},"outputs":[],"source":["from keras.models import load_model\n","model_final = load_model('model_50.h5')"]},{"cell_type":"markdown","id":"b7ba552b","metadata":{"id":"b7ba552b"},"source":["# Definitions"]},{"cell_type":"code","execution_count":null,"id":"173ed65b","metadata":{"id":"173ed65b"},"outputs":[],"source":["max_length = 35"]},{"cell_type":"code","execution_count":null,"id":"7a1d8c18","metadata":{"id":"7a1d8c18"},"outputs":[],"source":["# Load tokenizer from pickle\n","with open('tokenizer.pkl', 'rb') as f:\n","    tokenizer = pickle.load(f)"]},{"cell_type":"code","execution_count":null,"id":"9335a746","metadata":{"id":"9335a746"},"outputs":[],"source":["def create_feature(image):\n","  # Convert image pixels to numpy array\n","  image = img_to_array(image)\n","  # Reshape data for model\n","  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","  # Preprocess image for vgg\n","  image = preprocess_input(image)\n","  # Extract features\n","  feature = model_vgg.predict(image, verbose=0)\n","  # Store feature\n","  return feature"]},{"cell_type":"code","execution_count":null,"id":"f6d43f84","metadata":{"id":"f6d43f84"},"outputs":[],"source":["def idx_to_word(integer, tokenizer):\n","  for word, index in tokenizer.word_index.items():\n","      if index == integer:\n","        return word\n","  return None"]},{"cell_type":"code","execution_count":null,"id":"eee131a8","metadata":{"id":"eee131a8"},"outputs":[],"source":["# Generate caption for an image (using final model)\n","def predict_caption(model, image, tokenizer, max_length):\n","  # Add start tag for generation process\n","  in_text = 'startseq'\n","  # Iterate over the max length of sequence\n","  for i in range(max_length):\n","    # Encode input sequence\n","    sequence = tokenizer.texts_to_sequences([in_text])[0]\n","    # Pad the sequence\n","    sequence = pad_sequences([sequence], max_length)\n","    # Predict next word\n","    yhat = model.predict([image, sequence], verbose=0)\n","    # Get index with high probability\n","    yhat = np.argmax(yhat)\n","    # Convert index to word\n","    word = idx_to_word(yhat, tokenizer)\n","    # Stop if word not found\n","    if word is None:\n","      break\n","    # Sppend word as input for generating next word\n","    in_text += \" \" + word\n","#     Stop if we reach end tag\n","    if word == 'endseq':\n","      break\n","  return in_text"]},{"cell_type":"code","execution_count":null,"id":"68fdc43e","metadata":{"id":"68fdc43e"},"outputs":[],"source":["def upload_img():\n","    \"\"\"\n","    A function to upload the image from the local computer to the application for \n","    interaction, we also reframe and adjust the picture with suitable size. \n","    \"\"\"\n","    global img, image_data\n","    for img_display in frame.winfo_children():\n","        img_display.destroy()\n","\n","    image_data = filedialog.askopenfilename(initialdir=\"/\", title=\"Choose an image\",\n","                                            filetypes=((\"all files\", \"*.*\"), (\"png files\", \"*.png\"), (\"jpg files\", \"*.jpg\")))\n","    basewidth = 300\n","    img = Image.open(image_data)\n","    wpercent = (basewidth / float(img.size[0]))\n","    hsize = int((float(img.size[1]) * float(wpercent)))\n","    img = img.resize((basewidth, hsize), Image.ANTIALIAS)\n","    img = ImageTk.PhotoImage(img)\n","    file_name = image_data.split('/')\n","    #panel = tk.Label(frame, text=str(file_name[len(file_name) - 1]).upper()).pack()\n","    panel_image = tk.Label(frame, image=img).pack()"]},{"cell_type":"code","execution_count":null,"id":"b14ea61e","metadata":{"id":"b14ea61e"},"outputs":[],"source":["def captioning():\n","    \"\"\"\n","    A function where it uses the model to generate caption matching with the \n","    new picture, and stores the caption for output.\n","    \"\"\"\n","    original = Image.open(image_data)\n","    original = original.resize((224, 224), Image.ANTIALIAS)\n","    caption = predict_caption(model_final, create_feature(original), tokenizer, max_length)\n","    half_len = int(len(caption)//2)\n","    space_index = caption.find(\" \", half_len)\n","    caption1 = str(caption[9].upper() + caption[10:space_index])\n","    caption2 = str(caption[space_index+1:-7] + \".\")\n","    table1 = tk.Label(frame, text=(caption1), font=(\"Helvetica\", 12)).pack()\n","    table2 = tk.Label(frame, text=(caption2), font=(\"Helvetica\", 12)).pack()"]},{"cell_type":"markdown","id":"537bc9e7","metadata":{"id":"537bc9e7"},"source":["# GUI"]},{"cell_type":"code","execution_count":null,"id":"c4f6e979","metadata":{"id":"c4f6e979","outputId":"61edb011-d1d0-44fc-bf13-2135eb870e94"},"outputs":[{"name":"stderr","output_type":"stream","text":["Exception in Tkinter callback\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2916, in open\n","    fp.seek(0)\n","AttributeError: 'str' object has no attribute 'seek'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n","    return self.func(*args)\n","  File \"<ipython-input-21-78fcc81aa499>\", line 9, in upload_img\n","    img = Image.open(image_data)\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2918, in open\n","    fp = io.BytesIO(fp.read())\n","AttributeError: 'str' object has no attribute 'read'\n","Exception in Tkinter callback\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2916, in open\n","    fp.seek(0)\n","AttributeError: 'str' object has no attribute 'seek'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n","    return self.func(*args)\n","  File \"<ipython-input-21-78fcc81aa499>\", line 9, in upload_img\n","    img = Image.open(image_data)\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2918, in open\n","    fp = io.BytesIO(fp.read())\n","AttributeError: 'str' object has no attribute 'read'\n","Exception in Tkinter callback\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2916, in open\n","    fp.seek(0)\n","AttributeError: 'str' object has no attribute 'seek'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n","    return self.func(*args)\n","  File \"<ipython-input-21-78fcc81aa499>\", line 9, in upload_img\n","    img = Image.open(image_data)\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2918, in open\n","    fp = io.BytesIO(fp.read())\n","AttributeError: 'str' object has no attribute 'read'\n","Exception in Tkinter callback\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2916, in open\n","    fp.seek(0)\n","AttributeError: 'str' object has no attribute 'seek'\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"D:\\TDC\\New folder\\lib\\tkinter\\__init__.py\", line 1892, in __call__\n","    return self.func(*args)\n","  File \"<ipython-input-21-78fcc81aa499>\", line 9, in upload_img\n","    img = Image.open(image_data)\n","  File \"D:\\TDC\\New folder\\lib\\site-packages\\PIL\\Image.py\", line 2918, in open\n","    fp = io.BytesIO(fp.read())\n","AttributeError: 'str' object has no attribute 'read'\n"]}],"source":["root = tk.Tk()\n","root.title('IMAGE CAPTION GENERATOR')\n","# root.iconbitmap('icon.ico')\n","root.resizable(False, False)\n","tit = tk.Label(root, text=\"IMAGE CAPTION GENERATOR\", padx=25, pady=6, font=(\"Helvetica\", 14)).pack()\n","canvas = tk.Canvas(root, height=550, width=600, bg='#EA4630')\n","canvas.pack()\n","frame = tk.Frame(root, bg='#146B3A')\n","frame.place(relwidth=0.8, relheight=0.8, relx=0.1, rely=0.1)\n","chose_image = tk.Button(root, text='Choose Image',\n","                        padx=35, pady=15, font=(\"Helvetica\", 12),\n","                        fg=\"black\", bg=\"#F8B229\", command=upload_img, activebackground=\"#add8e6\")\n","chose_image.pack(side=tk.LEFT)\n","\n","caption_image = tk.Button(root, text='Classify Image',\n","                          padx=35, pady=15, font=(\"Helvetica\", 12),\n","                          fg=\"black\", bg=\"#F8B229\", command=captioning, activebackground=\"#add8e6\")\n","caption_image.pack(side=tk.RIGHT)\n","root.mainloop()"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"}},"nbformat":4,"nbformat_minor":5}