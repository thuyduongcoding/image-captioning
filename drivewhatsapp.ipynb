{"cells":[{"cell_type":"markdown","metadata":{"id":"D3Tt6k3Ed0z9"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JVnrpFFMRcle"},"outputs":[],"source":["# Import libraries\n","import os\n","import pickle\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.utils import to_categorical, plot_model  \n","from tensorflow.keras.layers import Input, Dense, LSTM, Embedding, Dropout, add"]},{"cell_type":"markdown","metadata":{"id":"MzXTkfVZeCP8"},"source":["# Extract image data features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-eoGm2qXRpSc"},"outputs":[],"source":["# Load vgg16 model\n","model = VGG16()\n","# Restructure the model\n","model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","# Summarize\n","# print(model.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JpOAavgMcFSk"},"outputs":[],"source":["# Load features from pickle\n","with open('features.pkl', 'rb') as f:\n","    features = pickle.load(f)"]},{"cell_type":"markdown","metadata":{"id":"s2nnAEDxeTYb"},"source":["# Load caption data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OTfODyo1cgHt"},"outputs":[],"source":["with open('captions.txt', 'r') as f:\n","    next(f)\n","    captions_doc = f.read()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["8543e42b3a3647ccb3e429e13199f402","90adb04132ca43d796ffb0d7e532f134","133485cf422240558342efaa3def299f","8e20bd1cc335446d90bf28af3b4ddb4d","665bfb74677f4cbc9896fc057a88ef53","92966c989f4f4e40b08fdc169258c937","30841370257a4835b72b71c234421a7f","7dcdbaaa4ebc4919ada6ad17f44c02d6","e65afa1fb09b450f891590add26c2b82","a7993c84d0ac48d0b6423a737302858c","bfaaf378c9f747088efdf639eac614df","04f07d2903a144688a6c91d562bbff54"]},"id":"ACgkGC3vcqyZ","outputId":"d45acc1e-de59-4f63-8505-e986b0f7b67a"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04f07d2903a144688a6c91d562bbff54","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/40456 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Create mapping of image to captions\n","mapping = {}\n","# Process lines\n","for line in tqdm(captions_doc.split('\\n')):\n","    # Split the line by comma(,)\n","    tokens = line.split(',')\n","    if len(line) < 2:\n","        continue\n","    image_id, caption = tokens[0], tokens[1:]\n","    # Remove extension from image ID\n","    image_id = image_id.split('.')[0]\n","    # Convert caption list to string\n","    caption = \" \".join(caption)\n","    # Create list if needed\n","    if image_id not in mapping:\n","        mapping[image_id] = []\n","    # Store the caption\n","    mapping[image_id].append(caption)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXN0nOMuc2Eo","outputId":"49f44cca-44d0-4e9a-d4b3-9f7909bd45bb"},"outputs":[{"data":{"text/plain":["8091"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["len(mapping)"]},{"cell_type":"markdown","metadata":{"id":"hoCvp_biegr7"},"source":["# Preprocess caption data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yz9kO3Utc3Ad"},"outputs":[],"source":["def clean(mapping):\n","    for key, captions in mapping.items():\n","        for i in range(len(captions)):\n","          # Take one caption at a time\n","          caption = captions[i]\n","          # Preprocessing steps\n","          # Convert to lowercase\n","          caption = caption.lower()\n","          # Delete digits, special chars, etc., \n","          caption = caption.replace('[^A-Za-z]', '')\n","          # Delete additional spaces\n","          caption = caption.replace('\\s+', ' ')\n","          # Add start and end tags to the caption\n","          caption = 'Caption: ' + \" \".join([word for word in caption.split() if len(word)>1]) + ' endseq'\n","          captions[i] = caption"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLirguBVc-Ql","outputId":"a2d166f8-e8cb-4f0f-bb88-1e7bb29bcdac"},"outputs":[{"data":{"text/plain":["['A child in a pink dress is climbing up a set of stairs in an entry way .',\n"," 'A girl going into a wooden building .',\n"," 'A little girl climbing into a wooden playhouse .',\n"," 'A little girl climbing the stairs to her playhouse .',\n"," 'A little girl in a pink dress going into a wooden cabin .']"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["# Before preprocess of text\n","mapping['1000268201_693b08cb0e']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NV0OPT_cdBrI"},"outputs":[],"source":["# Preprocess the text\n","clean(mapping)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aNi3rOevdE34","outputId":"bde5cd28-8cbf-45bb-a0e8-59c70a391020"},"outputs":[{"data":{"text/plain":["['Caption: child in pink dress is climbing up set of stairs in an entry way endseq',\n"," 'Caption: girl going into wooden building endseq',\n"," 'Caption: little girl climbing into wooden playhouse endseq',\n"," 'Caption: little girl climbing the stairs to her playhouse endseq',\n"," 'Caption: little girl in pink dress going into wooden cabin endseq']"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# After preprocess of text\n","mapping['1000268201_693b08cb0e']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jnt0wX9jdIP0"},"outputs":[],"source":["all_captions = []\n","for key in mapping:\n","    for caption in mapping[key]:\n","        all_captions.append(caption)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2M5HRArKdIYE","outputId":"97be58ec-82be-4529-e0be-820e3fc0affe"},"outputs":[{"data":{"text/plain":["40455"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(all_captions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d_LChBvdQA1"},"outputs":[],"source":["# Tokenize the text\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(all_captions)\n","vocab_size = len(tokenizer.word_index) + 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jUW_sKGtdScj","outputId":"1e7200ab-dfce-421c-f4c4-6c4c192d39cf"},"outputs":[{"data":{"text/plain":["8485"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["vocab_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-OC7Mh8HdVb5","outputId":"d43d5855-416c-4cf5-9f4a-831981e2468a"},"outputs":[{"data":{"text/plain":["35"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Get maximum length of the caption available\n","max_length = max(len(caption.split()) for caption in all_captions)\n","max_length"]},{"cell_type":"markdown","metadata":{"id":"Ud6403UmfDIZ"},"source":["# Split training and testing data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HpQ_vFimdZuI"},"outputs":[],"source":["image_ids = list(mapping.keys())\n","split = int(len(image_ids) * 0.90)\n","train = image_ids[:split]\n","test = image_ids[split:]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDWzySMkdd0k"},"outputs":[],"source":["# Create data generator to get data in batch (avoids session crash)\n","def data_generator(data_keys, mapping, features, tokenizer, max_length, vocab_size, batch_size):\n","  # Loop over images\n","  X1, X2, y = list(), list(), list()\n","  n = 0\n","  while 1:\n","    for key in data_keys:\n","      n += 1\n","      captions = mapping[key]\n","      # Process each caption\n","      for caption in captions:\n","        # Encode the sequence\n","        seq = tokenizer.texts_to_sequences([caption])[0]\n","        # Split the sequence into X, y pairs\n","        for i in range(1, len(seq)):\n","          # Split into input and output pairs\n","          in_seq, out_seq = seq[:i], seq[i]\n","          # Pad input sequence\n","          in_seq = pad_sequences([in_seq], maxlen=max_length)[0]\n","          # Encode output sequence\n","          out_seq = to_categorical([out_seq], \n","            num_classes=vocab_size)[0]\n","          # Store the sequences\n","          X1.append(features[key][0])\n","          X2.append(in_seq)\n","          y.append(out_seq)\n","      if n == batch_size:\n","          X1, X2, y = np.array(X1), np.array(X2), np.array(y)\n","          yield [X1, X2], y\n","          X1, X2, y = list(), list(), list()\n","          n = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7HMI-j3sXHa0"},"outputs":[],"source":["from keras.models import load_model\n","model_final = load_model('best_model.h5')"]},{"cell_type":"markdown","metadata":{"id":"aXP_chvSgqn-"},"source":["# Generate image captions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UxbcFuHGgtq8"},"outputs":[],"source":["def idx_to_word(integer, tokenizer):\n","  for word, index in tokenizer.word_index.items():\n","      if index == integer:\n","        return word\n","  return None"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LlAvKfg_g1-O"},"outputs":[],"source":["# Generate caption for an image\n","def predict_caption(model, image, tokenizer, max_length):\n","  # Add start tag for generation process\n","  in_text = 'Caption: '\n","  # Iterate over the max length of sequence\n","  for i in range(max_length):\n","    # Encode input sequence\n","    sequence = tokenizer.texts_to_sequences([in_text])[0]\n","    # Pad the sequence\n","    sequence = pad_sequences([sequence], max_length)\n","    # Predict next word\n","    yhat = model.predict([image, sequence], verbose=0)\n","    # Get index with high probability\n","    yhat = np.argmax(yhat)\n","    # Convert index to word\n","    word = idx_to_word(yhat, tokenizer)\n","    # Stop if word not found\n","    if word is None:\n","      break\n","    # Sppend word as input for generating next word\n","    in_text += \" \" + word\n","    # Stop if we reach end tag\n","    if word == 'endseq':\n","      break\n","  return in_text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QddQ9C4hXHa1"},"outputs":[],"source":["def create_feature(image_path):\n","  model = VGG16()\n","  model = Model(inputs=model.inputs, outputs=model.layers[-2].output)\n","  image = load_img(image_path, target_size=(224, 224))\n","  # convert image pixels to numpy array\n","  image = img_to_array(image)\n","  # reshape data for model\n","  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n","  # preprocess image for vgg\n","  image = preprocess_input(image)\n","  # extract features\n","  feature = model.predict(image, verbose=0)\n","  # store feature\n","  return feature"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VcvZkU_3XHa1"},"outputs":[],"source":["model_final = load_model('best_model.h5')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qMAOrlWaXHa2"},"outputs":[],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import cv2\n","def generate_caption_new(image_name, image_path):\n","  # load the image\n","  image = Image.open(image_path)\n","  # img_resize = cv2.resize(image, (500, 375))\n","  # predict the caption\n","  y_pred = predict_caption(model_final, create_feature(image_path), tokenizer, max_length)\n","  return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":306},"id":"WYQTCuBJ6E1N","outputId":"cf895ea1-5691-4502-b4bf-787ae484a7f7"},"outputs":[{"data":{"text/plain":["'Caption:  woman and woman sitting on the street while woman in black and black shorts endseq'"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["generate_caption_new('girl.jpg',r'C:\\Users\\Admin\\My Drive (luuquocanh242@gmail.com)\\fulbright\\CS1\\Project CS1\\CS101 Project\\girl.jpg')"]},{"cell_type":"markdown","source":["# Drive-WhatsApp"],"metadata":{"id":"sNUMmOikXRoY"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"yckN9VokXHa2"},"outputs":[],"source":["from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","gauth = GoogleAuth()           \n","drive = GoogleDrive(gauth)    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MxM3U2wCXHa2","outputId":"64c1fda7-2b50-4f33-e6c3-382f02849963"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading hiking.jpg file from GDrive (1/1)\n"]}],"source":["import pywhatkit\n","file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format('1j49N_WZpEU5EnPMNNxbs4Cx8G-nMdjZh')}).GetList()\n","\n","for i, file in enumerate(sorted(file_list, key = lambda x: x['title']), start=1):\n","\tprint('Downloading {} file from GDrive ({}/{})'.format(file['title'], i, len(file_list)))\n","\tfile.GetContentFile(file['title'])\n","caption_list=[]    \n","for i, file in enumerate(sorted(file_list, key = lambda x: x['title']), start=1):\n","#     print(file['title'])\n","    caption = generate_caption_new(file['title'],r'C:\\Users\\Admin\\My Drive (luuquocanh242@gmail.com)\\fulbright\\CS1\\Project CS1\\Import Image'+'\\\\'+str(file['title']))\n","    caption_list.append(str(i)+'. '+ str(caption))\n","final = '\\n'.join(caption_list)\n","pywhatkit.sendwhatmsg_instantly('+84917322299', final , 10, True, 10)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"widgets":{"application/vnd.jupyter.widget-state+json":{"133485cf422240558342efaa3def299f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dcdbaaa4ebc4919ada6ad17f44c02d6","max":40456,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e65afa1fb09b450f891590add26c2b82","value":40456}},"30841370257a4835b72b71c234421a7f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"665bfb74677f4cbc9896fc057a88ef53":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dcdbaaa4ebc4919ada6ad17f44c02d6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8543e42b3a3647ccb3e429e13199f402":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_90adb04132ca43d796ffb0d7e532f134","IPY_MODEL_133485cf422240558342efaa3def299f","IPY_MODEL_8e20bd1cc335446d90bf28af3b4ddb4d"],"layout":"IPY_MODEL_665bfb74677f4cbc9896fc057a88ef53"}},"8e20bd1cc335446d90bf28af3b4ddb4d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7993c84d0ac48d0b6423a737302858c","placeholder":"​","style":"IPY_MODEL_bfaaf378c9f747088efdf639eac614df","value":" 40456/40456 [00:00&lt;00:00, 404314.48it/s]"}},"90adb04132ca43d796ffb0d7e532f134":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_92966c989f4f4e40b08fdc169258c937","placeholder":"​","style":"IPY_MODEL_30841370257a4835b72b71c234421a7f","value":"100%"}},"92966c989f4f4e40b08fdc169258c937":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7993c84d0ac48d0b6423a737302858c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfaaf378c9f747088efdf639eac614df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e65afa1fb09b450f891590add26c2b82":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}